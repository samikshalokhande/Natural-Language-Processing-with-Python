{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXOx4I5oAK9Zpcw4GhOwMb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samikshalokhande/Natural-Language-Processing-with-Python/blob/main/2_Corpora_%26_Lexical_Resource.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Corpora:** Large body of linguistic data\n",
        "1. **Gutenberg Corpus:** contains some 25,000 free electronic books\n"
      ],
      "metadata": {
        "id": "ZYAQaNAVvOVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ2bmbJrv6Ue",
        "outputId": "486096cb-0758-44cc-97a7-7fa418341740"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVPFtF33ujAq",
        "outputId": "3bc48973-bc2b-4802-8edc-24f0bdaebf8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Gutenberg Corpus\n",
        "nltk.corpus.gutenberg.fileids()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emma = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
        "len(emma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSxSwNx3v4ga",
        "outputId": "80dad383-0c61-4235-fbc4-d942b6ffdc31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192427"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform task from nltk.book import * we need to do the following\n",
        "# concordance, similar, common_contexts, dispersion_plot, generate\n",
        "emma = nltk.Text(nltk.corpus.gutenberg.words('austen-emma.txt'))\n",
        "emma.concordance(\"die\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgDHC38EvwkJ",
        "outputId": "43cc954f-90ef-459f-f6bb-c59f10a58563"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 5 of 5 matches:\n",
            "ing made a push -- of having thrown a die ; and she imagined he was come to see\n",
            "ing -- fearing -- adoring -- ready to die if she refused him ; but flattering h\n",
            "a name behind her that would not soon die away . Perfect happiness , even in me\n",
            " folly , she has nothing to do but to die ; and when she stoops to be disagreea\n",
            "re , her pain and confusion seemed to die away with the words , and leave her w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "print(\"num_chars\",\"num_words\",\"num_sents\",\"num_vocab\",\"avg_word_len\", \"avg_sen_len\",\"lexical_diversity\", \"fileid\" )\n",
        "for fileid in gutenberg.fileids():\n",
        "  num_chars = len(gutenberg.raw(fileid))\n",
        "  num_words = len(gutenberg.words(fileid))\n",
        "  num_sents = len(gutenberg.sents(fileid))\n",
        "  num_vocab = len(set([w.lower() for w in gutenberg.words(fileid)]))\n",
        "  avg_word_len = num_chars/num_words\n",
        "  avg_sen_len = num_words/num_sents\n",
        "  lexical_diversity = num_words/num_vocab\n",
        "  print(num_chars,num_words,num_sents,num_vocab,avg_word_len, avg_sen_len,lexical_diversity, fileid )\n",
        "  # print(int(num_chars/num_words) , int(num_words/num_sents), int(num_words/num_vocab),  fileid )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E--GR3F4wexU",
        "outputId": "2b19c6ea-3e01-44cb-a901-13562c86810b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_chars num_words num_sents num_vocab avg_word_len avg_sen_len lexical_diversity fileid\n",
            "887071 192427 7752 7344 4.609909212324673 24.822884416924666 26.201933551198255 austen-emma.txt\n",
            "466292 98171 3747 5835 4.749793727271801 26.19989324793168 16.82450728363325 austen-persuasion.txt\n",
            "673022 141576 4999 6403 4.753785952421314 28.32086417283457 22.11088552241137 austen-sense.txt\n",
            "4332554 1010654 30103 12767 4.286881563819072 33.57319868451649 79.16143181640166 bible-kjv.txt\n",
            "38153 8354 438 1535 4.567033756284415 19.073059360730593 5.442345276872964 blake-poems.txt\n",
            "249439 55563 2863 3940 4.489300433741879 19.40726510653161 14.10228426395939 bryant-stories.txt\n",
            "84663 18963 1054 1559 4.464641670621737 17.99146110056926 12.163566388710713 burgess-busterbrown.txt\n",
            "144395 34110 1703 2636 4.233216065669891 20.029359953024077 12.940060698027315 carroll-alice.txt\n",
            "457450 96996 4779 8335 4.716173862839705 20.296296296296298 11.637192561487703 chesterton-ball.txt\n",
            "406629 86063 3806 7794 4.724783007796614 22.61245401996847 11.042211957916345 chesterton-brown.txt\n",
            "320525 69213 3742 6349 4.63099417739442 18.496258685195084 10.901401795558355 chesterton-thursday.txt\n",
            "935158 210663 10230 8447 4.4391184023772565 20.59266862170088 24.939386764531786 edgeworth-parents.txt\n",
            "1242990 260819 10059 17231 4.76571875515204 25.928919375683467 15.136614241773549 melville-moby_dick.txt\n",
            "468220 96825 1851 9021 4.835734572682675 52.309562398703406 10.73328899235118 milton-paradise.txt\n",
            "112310 25833 2163 3032 4.347539968257655 11.943134535367545 8.520118733509236 shakespeare-caesar.txt\n",
            "162881 37360 3106 4716 4.3597698072805136 12.028332260141662 7.921967769296014 shakespeare-hamlet.txt\n",
            "100351 23140 1907 3464 4.336689714779602 12.134242265338228 6.680138568129331 shakespeare-macbeth.txt\n",
            "711215 154883 4250 12452 4.591950052620365 36.44305882352941 12.438403469322198 whitman-leaves.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDkh2jm3xUbs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}